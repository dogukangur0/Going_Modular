{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu07qDWrc7XW+Uw42cUnmc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hzwLrnnbGs9V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "1sTQtL1vNjN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = pathlib.Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exist.\")\n",
        "else:\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  print(f\"{image_path} directory created.\")\n",
        "\n",
        "with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza, steak, sushi data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE9KPD5ENk6f",
        "outputId": "32693285-c469-4d1c-d159-12dab5c2d479"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory created.\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "def create_dataLoader(\n",
        "    train_dir,\n",
        "    test_dir,\n",
        "    transform,\n",
        "    batch_size,\n",
        "    num_workers : int = NUM_WORKERS\n",
        "):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "  \"\"\"\n",
        "  train_set = torchvision.datasets.ImageFolder(train_dir, transform)\n",
        "  test_set = torchvision.datasets.ImageFolder(test_dir, transform)\n",
        "\n",
        "  train_dataLoader = torch.utils.data.DataLoader(dataset = train_set, batch_size = batch_size, num_workers = num_workers, pin_memory = True, shuffle = True)\n",
        "  test_dataLoader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, num_workers = num_workers, pin_memory = True, shuffle = False)\n",
        "\n",
        "  classes = train_set.classes\n",
        "\n",
        "  return train_dataLoader, test_dataLoader, classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aME17LEGNp0I",
        "outputId": "2097e0c7-df07-4200-c086-f85f3539d1ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_build.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units*13*13, out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.classifier(self.conv_block2(self.conv_block1(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6uTl9IKOVpx",
        "outputId": "8b1d8623-fbfb-4a34-950d-db6a55222c85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/model_build.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train_test.py\n",
        "import torch\n",
        "\n",
        "def train_step(model, trainDataLoader, optimizer, loss_fn):\n",
        "  model.train()\n",
        "  total_train_loss = 0\n",
        "  total_train_acc = 0\n",
        "  for train_images, train_labels in trainDataLoader:\n",
        "    optimizer.zero_grad()\n",
        "    y_train_logits = model(train_images)\n",
        "    train_loss = loss_fn(y_train_logits, train_labels)\n",
        "    total_train_loss += train_loss.item()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    y_train_pred = torch.argmax(y_train_logits, dim=1)\n",
        "    total_train_acc += ((y_train_pred == train_labels).sum().item() / len(train_labels))\n",
        "  total_train_loss = total_train_loss / len(trainDataLoader)\n",
        "  total_train_acc = total_train_acc / len(trainDataLoader)\n",
        "\n",
        "  return total_train_loss, total_train_acc\n",
        "\n",
        "def test_step(model, testDataLoader, loss_fn):\n",
        "  model.eval()\n",
        "  total_test_loss = 0\n",
        "  total_test_acc = 0\n",
        "  with torch.inference_mode():\n",
        "    for test_images, test_labels in testDataLoader:\n",
        "      y_test_logits = model(test_images)\n",
        "      test_loss = loss_fn(y_test_logits, test_labels)\n",
        "      total_test_loss += test_loss.item()\n",
        "      y_test_pred = torch.argmax(y_test_logits, dim = 1)\n",
        "      total_test_acc += ((y_test_pred == test_labels).sum().item() / len(test_labels))\n",
        "    total_test_loss = total_test_loss / len(testDataLoader)\n",
        "    total_test_acc = total_test_acc / len(testDataLoader)\n",
        "\n",
        "  return total_test_loss, total_test_acc\n",
        "\n",
        "def train_model(model, trainDataLoader, testDataLoder, optimizer, loss_fn, epochs):\n",
        "  results = {\n",
        "      \"train_loss\" : [],\n",
        "      \"train_acc\" : [],\n",
        "      \"test_loss\" : [],\n",
        "      \"test_acc\" : []\n",
        "  }\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_loss, train_acc = train_step(model, trainDataLoader, optimizer, loss_fn)\n",
        "    test_loss, test_acc = test_step(model, testDataLoder, loss_fn)\n",
        "    print(f\"Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7al-QLCOdGm",
        "outputId": "3733f0b9-d2a6-4ad5-e4bb-e4ba4622df4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module, target_dir: str, model_name: str):\n",
        "  \"\"\"\n",
        "      Args:\n",
        "            model: A target PyTorch model to save.\n",
        "            target_dir: A directory for saving the model to.\n",
        "            model_name: A filename for the saved model. Should include either \".pth\" or \".pt\" as the file extension.\n",
        "  \"\"\"\n",
        "  target_dir_path = Path(target_dir)\n",
        "  target_dir_path.mkdir(parents = True, exist_ok = True)\n",
        "\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\")\n",
        "  model_save_path = target_dir_path / model_name\n",
        "  print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "  torch.save(obj = model.state_dict(), f = model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVJB2rd1OkC4",
        "outputId": "bae04287-b23d-4b6c-ddeb-adbdba3cb50c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/train.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from pathlib import Path\n",
        "from timeit import default_timer as timer\n",
        "import data_setup, model_build, train_test, utils\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "train_dir = Path(\"data/pizza_steak_sushi/train\")\n",
        "test_dir = Path(\"data/pizza_steak_sushi/test\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_dataLoader, test_DataLoader, classes = data_setup.create_dataLoader(train_dir,\n",
        "                                                                          test_dir,\n",
        "                                                                          transform,\n",
        "                                                                          batch_size = BATCH_SIZE)\n",
        "\n",
        "model_0 = model_build.TinyVGG(input_shape = 3, hidden_units = HIDDEN_UNITS, output_shape = len(classes))\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model_0.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "start_time = timer()\n",
        "train_test.train_model(model_0, train_dataLoader, test_DataLoader, optimizer, loss_fn, NUM_EPOCHS)\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
        "utils.save_model(model_0, target_dir = \"models\", model_name = \"05_going_modular_script_mode_tinyvgg_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxaRS2t8OuaK",
        "outputId": "297b1ab1-d1e7-4516-9f0d-ecb3e60a8a12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsTTlqhoOyRJ",
        "outputId": "7de3add2-738f-4804-c89e-7f9f6c80b2ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 1.0993, Train Acc: 0.3086 | Test Loss: 1.1117, Test Acc: 0.2917\n",
            "Epoch: 2, Train Loss: 1.1031, Train Acc: 0.3047 | Test Loss: 1.1180, Test Acc: 0.1979\n",
            "Epoch: 3, Train Loss: 1.0801, Train Acc: 0.5117 | Test Loss: 1.0781, Test Acc: 0.4129\n",
            "Epoch: 4, Train Loss: 1.0378, Train Acc: 0.5820 | Test Loss: 1.0728, Test Acc: 0.4318\n",
            "Epoch: 5, Train Loss: 1.0096, Train Acc: 0.5508 | Test Loss: 1.1111, Test Acc: 0.3125\n",
            "Epoch: 6, Train Loss: 1.0658, Train Acc: 0.3906 | Test Loss: 1.0764, Test Acc: 0.2907\n",
            "Epoch: 7, Train Loss: 0.9634, Train Acc: 0.6445 | Test Loss: 0.9994, Test Acc: 0.4631\n",
            "Epoch: 8, Train Loss: 0.9057, Train Acc: 0.6250 | Test Loss: 0.9783, Test Acc: 0.4631\n",
            "Epoch: 9, Train Loss: 1.0250, Train Acc: 0.5273 | Test Loss: 0.9746, Test Acc: 0.4328\n",
            "Epoch: 10, Train Loss: 1.0015, Train Acc: 0.4766 | Test Loss: 0.9778, Test Acc: 0.4640\n",
            "[INFO] Total training time: 17.666 seconds\n",
            "[INFO] Saving model to: models/05_going_modular_script_mode_tinyvgg_model.pth\n"
          ]
        }
      ]
    }
  ]
}