{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPagcFyCQ3Vz3jAX3X2bJd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hzwLrnnbGs9V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "1sTQtL1vNjN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = pathlib.Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exist.\")\n",
        "else:\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "  print(f\"{image_path} directory created.\")\n",
        "\n",
        "with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizza, steak, sushi data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE9KPD5ENk6f",
        "outputId": "32693285-c469-4d1c-d159-12dab5c2d479"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory created.\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "def create_dataLoader(\n",
        "    train_dir,\n",
        "    test_dir,\n",
        "    transform,\n",
        "    batch_size,\n",
        "    num_workers : int = NUM_WORKERS\n",
        "):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "  \"\"\"\n",
        "  train_set = torchvision.datasets.ImageFolder(train_dir, transform)\n",
        "  test_set = torchvision.datasets.ImageFolder(test_dir, transform)\n",
        "\n",
        "  train_dataLoader = torch.utils.data.DataLoader(dataset = train_set, batch_size = batch_size, num_workers = num_workers, pin_memory = True, shuffle = True)\n",
        "  test_dataLoader = torch.utils.data.DataLoader(dataset = test_set, batch_size = batch_size, num_workers = num_workers, pin_memory = True, shuffle = False)\n",
        "\n",
        "  classes = train_set.classes\n",
        "\n",
        "  return train_dataLoader, test_dataLoader, classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aME17LEGNp0I",
        "outputId": "2097e0c7-df07-4200-c086-f85f3539d1ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/model_build.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.conv_block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.conv_block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size = 3, stride = 1, padding = 0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features = hidden_units*13*13, out_features = output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.classifier(self.conv_block2(self.conv_block1(x)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6uTl9IKOVpx",
        "outputId": "8b1d8623-fbfb-4a34-950d-db6a55222c85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/model_build.py\n"
          ]
        }
      ]
    }
  ]
}